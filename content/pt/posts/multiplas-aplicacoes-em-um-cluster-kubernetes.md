---
title: "M√∫ltiplas aplica√ß√µes em um cluster Kubernetes"
url: multiplas-aplicacoes-em-um-kluster-kubernetes
date: "2020-03-29T13:29:17-03:00"
lastmod: "2020-03-29T13:29:17-03:00"
tags: ["gcp", "laravel", "prometheus"]
categories: ["devops", "kubernetes"]
imgs: ["/../multiple-applications-in-one-kubernetes-cluster.svg"]
cover: "/multiple-applications-in-one-kubernetes-cluster.svg"
readingTime: true
toc: true
comments: true
justify: false
single: false
license: ""
draft: true
translationKey: "multiple-applications-in-one-kubernetes-cluster"
---

Neste post mostro como preparei m√∫ltiplas aplica√ß√µes para deploy em um √∫nico cluster kubernetes e tamb√©m: o motivo da
escolha do kubernetes, os benef√≠cios, as dificuldades enfrentadas e os pr√≥ximos passos.

<!--more-->

---

T√≥picos:

- [O problema inicial](#o-problema-inicial)
- [Por que Kubernetes?](#por-que-kubernetes)
- [Preparando os containers](#preparando-os-containers)
- [Preparando os manifestos](#preparando-os-manifestos)
- [Criando o cluster kubernetes](#criando-o-cluster-kubernetes)
- [Realizando o deploy dos manifestos](#realizando-o-deploy-dos-manifestos)
- [Adicionando certificados SSL auto gerenciados](#adicionando-certificados-ssl-auto-gerenciados)
- [Automatizando o processo de teste e deploy com um pipeline CI/CD](#automatizando-o-processo-de-testes-e-deploy-com-um-pipeline-de-cicd)
- [Monitorando o cluster com Kontena Lens e m√©tricas Prometheus](#monitorando-o-cluster-com-kontena-lens-e-metricas-prometheus)
- [Problemas identificados](#problemas-identificados)
- [Pr√≥ximos passos](#proximos-passos)

---

## O problema inicial

Temos pelo menos 5 aplica√ß√µes principais rodando no _[Google Cloud Platform (GCP)](https://cloud.google.com)_ e tamb√©m
algumas fun√ß√µes que foram desacopladas de uma api e hoje s√£o executadas a partir de _[google functions](https://cloud.google.com/functions)_, acessadas pelas aplica√ß√µes principais.

Tr√™s dessas aplica√ß√µes principais rodavam individualmente (uma aplica√ß√£o por VM) em VMs do tipo n1-standard-1 (1vCPU e 3,75GB de RAM). Todas as aplica√ß√µes containerizadas e o deploy em produ√ß√£o realizado por um simples _docker-compose up -d_

Mesmo com todo o processo de deploy automatizado, sem gerar dores de cabe√ßa, `a m√° utiliza√ß√£o dos recursos` me incomodava:

- Uma das aplica√ß√µes (painel de administra√ß√£o, pouqu√≠ssimas pessoas com acesso) consumia no m√°ximo 10% da CPU somando
  todos os containers (nginx, app, queue, redis, certbot) e no m√°ximo 2 dos 3,75GB de RAM.
- Uma segunda aplica√ß√£o com m√©tricas bem parecidas com as de cima.
- Uma terceira aplica√ß√£o, com situa√ß√£o oposta as de cima, com m√©tricas recomendando o upgrade da VM para pelo menos 6GB
  de RAM. Essa aplica√ß√£o executa jobs em queues, pode ficar alguns minutos sem receber nenhum novo job e n√£o exigir
  recursos de hardware, por√©m, quando recebe um novo job ela deve executar todos rapidamente, al√©m de poder receber novos
  jobs enquanto executa o antigo e j√° ter que iniciar a execu√ß√£o desse novo job sem espera. No framework utilizado nessa aplica√ß√£o (Laravel), cada worker utiliza pelo menos 32MB de RAM, se configurarmos um valor m√°ximo de 120 workers, j√°
  s√£o necess√°rios pelo menos 3840MB de mem√≥ria RAM, excedendo os 3,75GB de RAM dessa VM. Al√©m do fato de muitas vezes
  os 120 workers n√£o serem suficientes para uma entrega r√°pida, ocasionando em um wait time longo para executar os jobs
  nas queues:

  ![Longo tempo de espera para execu√ß√£o dos jobs no horizon](/horizon-queue-long-wait-time.png)

  Essa aplica√ß√£o definivamente precisava de mais recursos enquanto as outras duas citadas anteriormente n√£o utilizavam
  todos os recursos dispon√≠veis.

- Uma quarta aplica√ß√£o, um MVP (_Minimum viable product_) rodando em um √∫nico container no _[cloud.run](https://cloud.run)_, j√° estava validada e precisava evoluir com implementa√ß√£o de queues e cache por exemplo. Como o cloud.run √© feito para conte√∫do _stateless_ e n√£o possui acesso a redis (pelo menos n√£o de forma f√°cil, sem ter que expor o redis de alguma VM por exemplo), era necess√°rio tir√°-lo dali.

- Uma quinta aplica√ß√£o, tamb√©m em container √∫nico, rodava bem no cloud.run e, diferentemente da anterior n√£o precisa de conex√£o com queues. Por√©m, como possui muitos acessos no cloud.run e o tempo de execu√ß√£o de CPU de cada request dessa aplica√ß√£o √© alto, os custos no cloud.run come√ßaram a incomodar (abaixo os pre√ßos do cloud.run com e sem free tier):

  ![Cloud Run Pricing](/cloud-run-pricing.png)

Uma solu√ß√£o vi√°vel para otimiza√ß√£o da utiliza√ß√£o de recursos seria executar as aplica√ß√µes num cluster, possuindo assim o
controle de quanto hardware dedicar a cada aplica√ß√£o e abrindo possibilidade para escalabilidade da terceira aplica√ß√£o
mencionada anteriormente. Para orquestrar os cont√¢iners no cluster, dentre as op√ß√µes dispon√≠veis eu teria que escolher
bem entre duas: Swarm ou Kubernetes, pois possu√≠a um pouco de conhecimento pr√©vio de ambas as ferramentas.

## Por que Kubernetes?

Gerenciar um cluster √© dif√≠cil, aplicar patches de seguran√ßa, auto reparo, auto upgrade, auto scaling e garantir
disponibilidade s√£o s√≥ alguns dos exemplos do que ter√≠amos que manter caso opt√°ssemos por gerenci√°-lo.

Dentre as op√ß√µes de cluster citadas anteriormente (Swarm e Kubernetes), nosso cloud provider disponibiliza apenas o servi√ßo
de gerenciamento de Kubernetes (na minha opini√£o, um dos melhores e mais robustos, talvez porque eles projetaram o Kubernetes e a maioria dos seus servi√ßos rodam no mesmo). O servi√ßo √© o Google Kubernetes Engine (GKE) e [oferece um plano gratuito para um cluster zonal](https://cloud.google.com/kubernetes-engine#pricing), atendendo nossas necessidades.

Os custos previstos:

- 2 VMs [e2-standard-2](https://cloud.google.com/blog/products/compute/google-compute-engine-gets-new-e2-vm-machine-types) com 2vCPU e 8GB de ram cada, totalizando um cluster com 4vCPU e 16GB de RAM. Com um contrato de [desconto por uso cont√≠nuo](https://cloud.google.com/compute/docs/instances/signing-up-committed-use-discounts) de 3 anos, a previs√£o mensal de custo √© de aproximadamente `45 USD`.
- Loadbalancer http/https, 1 at√© 5 regras de forwarding custam aproximadamente `18 USD`.

Bancos de dados, buckets e outros servi√ßos gerenciados do google n√£o entram na conta pois n√£o foram alterados e seus custos continuaram os mesmos.

## Preparando os containers

Como dito no primeiro t√≥pico, as aplica√ß√µes j√° rodavam containerizadas. Um container dedicado a aplica√ß√£o web, um para as queues, um para a execu√ß√£o de schedules, um container redis e um nginx. O container certbot foi descartado pois foi adotada outra abordagem para gerenciamento dos certificados SSL.

Caso voc√™ ainda n√£o tenha containerizado sua aplica√ß√£o, prepare-a de modo que respeite o [Twelve-Factor App](https://12factor.net).

## Preparando os manifestos

Aqui vem o primeiro baque pra quem era acostumado a subir o ambiente de produ√ß√£o inteiro com um √∫nico arquivo
docker-compose.yaml üôÉ

<p align="center">
  <img src="/k8s-manifests.png" width="400px">
</p>

Mostrarei o prop√≥sito de cada arquivo. Veja detalhes e conceitos do Kubernetes em sua [documenta√ß√£o](https://kubernetes.io/docs/concepts/).

A infraestrutura da aplica√ß√£o √© definida como c√≥digo, os controllers do Kubernetes checam em loop `se o estado atual da aplica√ß√£o √© igual ao estado definido via c√≥digo`, e caso n√£o seja, aplica as modifica√ß√µes necess√°rias.

Os manifestos podem ser definidos em YAML ou JSON, as extens√µes `.yaml`, `.yml` e `.json` s√£o aceitas. Coloco todos no mesmo diret√≥rio para facilitar o deploy com o comando `kubectl apply -f k8s/`.

###### 01-namespace.yaml

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: yourapp1
  labels:
    name: yourapp1

---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota
  namespace: yourapp1
spec:
  hard:
    requests.cpu: 100m
    requests.memory: 512Mi
    limits.cpu: 200m
    limits.memory: 1024Mi
```

Neste arquivo defino o [Namespace](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/) da aplica√ß√£o. Com namespaces √© poss√≠vel definir o escopo das aplica√ß√µes. Assim √© poss√≠vel executar v√°rias aplica√ß√µes diferentes no mesmo cluster sem que interfiram uma na outra (a comunica√ß√£o entre namespaces ainda √© poss√≠vel atrav√©s de servi√ßos expostos como mostrarei). Outro exemplo da utilidade de namespaces √© separar ambientes de `staging` e `production`. Por padr√£o, caso
namespaces n√£o sejam definidos, os deploys s√£o realizados no namespace `default`.

No mesmo arquivo defino um deploy do tipo [Resource Quota](https://kubernetes.io/docs/concepts/policy/resource-quotas/), nele √© poss√≠vel definir os recursos e limites de recursos solicitados pelo namespace. No exemplo, defino que:

- `requests.cpu: 100m` - todos os componentes do namespace podem requisitar (somados) no m√°ximo 100 millicores de cpu (1vCPU = 1000m, valores de cpu podem ser definidos de 1m a 1000m).

- `requests.memory: 512Mi` - todos os componentes do namespace podem requisitar (somados) no m√°ximo 512Mi de mem√≥ria (1 Mebibyte (MiB) = (1024)^2 bytes = 1048576 bytes).

- `limits.cpu: 200m` - todos os componentes do namespace (apesar de requisitar 100m de cpu definidos anteriormente)
  podem utilizar o m√°ximo 200 millicores de cpu.

- `limits.memory: 1024Mi` - todos os componentes do namespace (apesar de requisitar 512Mi de mem√≥ria definidos anteriormente) podem utilizar no m√°ximo 1024Mi de mem√≥ria.

Quando os limites de cpu definidos s√£o atingidos, a aplica√ß√£o come√ßa a sofrer `throttled` de cpu, ou seja, sua performance √© afetada.

Quando os limites de mem√≥ria s√£o atingidos, n√£o √© poss√≠vel "comprimir" a mem√≥ria como √© feito com cpu, e seu [Pod](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/) √© terminado.

Quando um deploy de uma nova vers√£o da sua aplica√ß√£o √© feita, caso o limite de cpu ou mem√≥ria seja excedido, os pods n√£o seram executados e ficar√£o com o estado [Evicted](https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#eviction-policy).

A defini√ß√£o de ResourceQuota para um namespace √© opcional, por√©m garante que uma aplica√ß√£o n√£o consuma recursos demasiadamente.

###### 02-nfs-server-deployment.yaml

```yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nfs-server
  namespace: yourapp1
spec:
  replicas: 1
  selector:
    matchLabels:
      name: nfs-server
  template:
    metadata:
      labels:
        name: nfs-server
    spec:
      containers:
        - name: nfs-server
          image: gcr.io/google_containers/volume-nfs:latest
          ports:
            - name: nfs
              containerPort: 2049
            - name: mountd
              containerPort: 20048
            - name: rpcbind
              containerPort: 111
          securityContext:
            privileged: true
          resources:
            requests:
              cpu: 1m
              memory: 168Mi
            limits:
              cpu: 2m
              memory: 192Mi
          volumeMounts:
            - name: data
              mountPath: /exports

      volumes:
        - name: data
          gcePersistentDisk:
            pdName: yourapp1-nfs-disk
            fsType: ext4
```

Neste arquivo defino o deployment de um volume NFS, j√° que o padr√£o [GCEPersistentDisk](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes) do GKE n√£o suporta o tipo de acesso `ReadWriteMany` para ser lido e escrito por v√°rios nodes ao mesmo tempo.

Este volume ser√° usado para persistir os dados do redis e tamb√©m as p√°ginas est√°ticas que s√£o geradas a partir do container app e compartilhadas com o container nginx.

Alguns detalhes do arquivo:

- O namespace deve ser o mesmo definido anteriormente para que o escopo do deploy seja o mesmo namespace.
- Ele possui apenas uma r√©plica.
- As requests e limits de cpu desse deployment podem ser bem pequenas (mostro mais a frente como analisar).
- O volume √© montado no path /exports do disco.
- O disco definido em `pdName` nos volumes deve ser criado anteriormente com:

```bash
gcloud compute disks create --size=1GB --zone=us-central1-a --type=pd-ssd yourapp1-nfs-disk
```

###### 03-nfs-server-service.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nfs-server
  namespace: yourapp1
spec:
  ports:
    - name: nfs
      port: 2049
    - name: mountd
      port: 20048
    - name: rpcbind
      port: 111
  selector:
    name: nfs-server
```

O service acima √© o respons√°vel por [expor o deployment criado anteriormente para ser acessado pelos outros pods](https://kubernetes.io/docs/concepts/services-networking/service/). O servi√ßo √© exposto com ClusterIp, apenas para outros pods, e n√£o para a internet.

Lembre-se de definir o `selector` do service com o mesmo valor definido nas `labels` do selector no deployment.

###### 04-redis-statefulset.yaml

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
  namespace: yourapp1
spec:
  serviceName: redis
  selector:
    matchLabels:
      name: redis
  template:
    metadata:
      name: redis
      labels:
        name: redis
    spec:
      containers:
        - name: redis
          image: redis:5.0.5-alpine
          ports:
            - containerPort: 6379
          resources:
            requests:
              cpu: 5m
              memory: 14Mi
            limits:
              cpu: 5m
              memory: 16Mi
          volumeMounts:
            - name: data
              mountPath: /data
      volumes:
        - name: data
          nfs:
            server: nfs-server.yourapp1.svc.cluster.local
            path: "/redis/data"
```

O deploy do redis √© do tipo [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/), o volume pode acessar diretamente o servi√ßo deployado anteriormente via `<service>`.`<namespace>`.svc.cluster.local.

###### 05-redis-service.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: yourapp1
spec:
  ports:
    - port: 6379
      protocol: TCP
  selector:
    name: redis
```

Exp√µe o redis com ClusterIp para ser acessado pelos outros pods.

###### 06-app-deployment.yaml

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
  namespace: yourapp1
  labels:
    name: app
  annotations:
    secret.reloader.stakater.com/reload: "env"
spec:
  replicas: 2
  revisionHistoryLimit: 1
  selector:
    matchLabels:
      name: app
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 50%
  template:
    metadata:
      labels:
        name: app
    spec:
      containers:
        - name: app
          image: gcr.io/yourproject/yourapp1:TAG_NAME
          command: ["/bin/bash"]
          args:
            - -c
            - |
              sleep 12
              php artisan migrate --force
              php artisan optimize
              php artisan view:cache
              ln -s public html
              ln -s /var/www /usr/share/nginx
              /usr/local/sbin/php-fpm
          envFrom:
            - secretRef:
                name: env
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
            successThreshold: 1
            tcpSocket:
              port: 9000
          ports:
            - containerPort: 9000
          resources:
            requests:
              cpu: 20m
              memory: 320Mi
            limits:
              cpu: 50m
              memory: 512Mi
          volumeMounts:
            - name: static
              mountPath: /static
            - name: cache-html
              mountPath: /var/www/public/cache-html
          lifecycle:
            postStart:
              exec:
                command: ["/bin/bash", "-c", "cp -r /var/www/public/. /static"]

        - name: cloudsql-proxy
          image: gcr.io/cloudsql-docker/gce-proxy:latest
          command:
            [
              "/cloud_sql_proxy",
              "-instances=yourproject:cloudsql-region:yourproject=tcp:5432",
              "-credential_file=/secrets/cloudsql/cloudsqlproxy.json",
            ]
          resources:
            requests:
              cpu: 1m
              memory: 8Mi
            limits:
              cpu: 10m
              memory: 16Mi
          volumeMounts:
            - name: cloudsql-instance-credentials
              mountPath: /secrets/cloudsql
              readOnly: true

      volumes:
        - name: static
          nfs:
            server: nfs-server.yourapp1.svc.cluster.local
            path: "/static"
        - name: cache-html
          nfs:
            server: nfs-server.yourapp1.svc.cluster.local
            path: "/cache-html"
        - name: cloudsql-instance-credentials
          secret:
            secretName: cloudsql-instance-credentials
```

Respons√°vel pelo deploy da aplica√ß√£o laravel com fpm, em `annotations` temos uma anota√ß√£o `secret.reloader.stakater.com/reload: "env"` que ir√° realizar o deploy de um novo pod `sempre que a secret com nome env` for atualizada. Esse comportamento n√£o √© padr√£o do kubernetes e para habilit√°-lo, instalamos um controller chamado [Reloader](https://github.com/stakater/Reloader) com o comando:

```bash
kubectl apply -f https://raw.githubusercontent.com/stakater/Reloader/master/deployments/kubernetes/reloader.yaml
```

- `replicas: 2` - definimos que o deploy ir√° criar 2 pods
- `revisionHistoryLimit: 1` - s√≥ teremos acesso a uma vers√£o anterior a atual para rollback

Em `strategy`:

- `type: RollingUpdate` - Nosso deploy √© do tipo [Rolling Update](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#rolling-update-deployment)
- `maxSurge: 1` - S√≥ pode surgir um novo pod por vez
- `maxUnavailable: 50%` - No m√≠nimo metade dos pods devem estar dispon√≠veis durante o deploy, ou seja, no exemplo com `replicas: 2` e `maxSurge: 1`, um novo pod surgir√°, ent√£o um pod antigo ser√° terminado (respeitando o `maxUnavailable: 50%`), ent√£o um novo pod surgir√°, e o √∫ltimo pod antigo ser√° terminado.

Em `containers`:

Esse pod possui 2 containers, o app principal e um sidecar (um proxy para conex√£o com o banco de dados no Google Cloud SQL).

No primeiro container `app` temos:

- `commands:` e `args:` - s√£o os comandos que ser√£o executados pelo nosso container, o `sleep` inicial serve para aguardar at√© que o container sidecar esteja dispon√≠vel. Na vers√£o `1.18` em diante [esse sleep n√£o ser√° mais necess√°rio](https://banzaicloud.com/blog/k8s-sidecars/).
- `envFrom:` - injetamos nossas vari√°veis de ambiente (mostrarei como cri√°-las no t√≥pico [Automatizando o processo de teste e deploy com um pipeline CI/CD](#automatizando-o-processo-de-testes-e-deploy-com-um-pipeline-de-cicd)).
- `readinessProbe:` - O container s√≥ receber√° tr√°fego ap√≥s uma conex√£o TCP bem sucedida com o container na porta 9000.
- `volumeMounts:` - O volume static compartilha assets entre o app e o nginx. O volume cache-html armazena algumas p√°ginas de forma est√°tica geradas a partir do conte√∫do din√¢mico, evitando a renderiza√ß√£o a todo momento.

No sidecar container `cloudsql-proxy` fazemos a autentica√ß√£o com o uso de um secret que tamb√©m mostro como cri√°-la no t√≥pico [Automatizando o processo de teste e deploy com um pipeline CI/CD](#automatizando-o-processo-de-testes-e-deploy-com-um-pipeline-de-cicd).

###### 07-app-hpa.yaml

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: app
  namespace: yourapp1
spec:
  maxReplicas: 3
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 90
    - type: Resource
      resource:
        name: memory
        targetAverageUtilization: 90
```

O [Horizontal Pod Autoscaler (HPA)](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/) escala automaticamente o n√∫mero de pods do nosso deployment. No exemplo em 06-app-deployment.yaml, nosso deployment foi feito com duas r√©plicas, o HPA acima consegue ir√° escalar esse deployment para 1 ou 3 r√©plicas baseado na m√©dia de utiliza√ß√£o de cpu e mem√≥ria do deployment.

###### 08-app-service.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  name: app
  namespace: yourapp1
  labels:
    name: app
spec:
  ports:
    - protocol: TCP
      port: 9000
  selector:
    name: app
```

Exp√µe o app com ClusterIp para ser acessado pelos outros pods.

###### 09-queue-deployment.yaml

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: queue
  namespace: yourapp1
  labels:
    name: queue
  annotations:
    secret.reloader.stakater.com/reload: "env"
spec:
  replicas: 1
  revisionHistoryLimit: 1
  selector:
    matchLabels:
      name: queue
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 50%
  template:
    metadata:
      labels:
        name: queue
    spec:
      containers:
        - name: queue
          image: gcr.io/yourproject/yourapp1:TAG_NAME
          command: ["/bin/bash"]
          args:
            - -c
            - |
              php artisan config:cache
              php artisan horizon --quiet
          envFrom:
            - secretRef:
                name: env
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 150m
              memory: 512Mi

        - name: cloudsql-proxy
          image: gcr.io/cloudsql-docker/gce-proxy:latest
          command:
            [
              "/cloud_sql_proxy",
              "-instances=yourproject:cloudsql-region:yourproject=tcp:5432",
              "-credential_file=/secrets/cloudsql/cloudsqlproxy.json",
            ]
          resources:
            requests:
              cpu: 1m
              memory: 8Mi
            limits:
              cpu: 10m
              memory: 16Mi
          volumeMounts:
            - name: cloudsql-instance-credentials
              mountPath: /secrets/cloudsql
              readOnly: true

      volumes:
        - name: cloudsql-instance-credentials
          secret:
            secretName: cloudsql-instance-credentials
```

Os conceitos s√£o os mesmos do [06-app-deployment.yaml](#06-app-deploymentyaml), por√©m iniciamos com apenas uma r√©plica e o HPA a seguir controla a necessidade de outras r√©plicas.

###### 10-queue-hpa.yaml

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: queue
  namespace: yourapp1
spec:
  maxReplicas: 2
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: queue
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 100
    - type: Resource
      resource:
        name: memory
        targetAverageUtilization: 90
```

Os conceitos s√£o os mesmos do [07-app-hpa.yaml](#07-app-hpayaml)

## Criando o cluster Kubernetes

## Realizando o deploy dos manifestos

## Adicionando certificados SSL auto gerenciados

## Automatizando o processo de testes e deploy com um pipeline de CI/CD

## Monitorando o cluster com Kontena Lens e m√©tricas Prometheus

## Problemas identificados

## Pr√≥ximos passos
